{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOsRtiZXca3QYn8+XVBUBMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devsingh02/Data-Science/blob/master/Text_Generation(topsis).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Newcode"
      ],
      "metadata": {
        "id": "FIFFDNtSbJYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def topsis(models, metrics, weights):\n",
        "  \"\"\"\n",
        "  Applies TOPSIS method to select the best pretrained model for text generation.\n",
        "\n",
        "  Args:\n",
        "      models: A list of dictionaries, where each dictionary represents a model and\n",
        "              contains keys for each metric.\n",
        "      metrics: A list of strings, representing the names of the metrics.\n",
        "      weights: A list of floats, representing the weights for each metric.\n",
        "\n",
        "  Returns:\n",
        "      The index of the best model in the `models` list.\n",
        "  \"\"\"\n",
        "\n",
        "  # Create the decision matrix.\n",
        "  decision_matrix = np.array([[model[metric] for metric in metrics] for model in models])\n",
        "\n",
        "  # Normalize the decision matrix.\n",
        "  normalized_matrix = (decision_matrix - decision_matrix.min(axis=0)) / (decision_matrix.max(axis=0) - decision_matrix.min(axis=0))\n",
        "\n",
        "  # Calculate the weighted normalized decision matrix.\n",
        "  weighted_normalized_matrix = normalized_matrix * np.diag(weights)\n",
        "\n",
        "  # Find the ideal and negative ideal solutions.\n",
        "  ideal_solution = np.ones_like(weighted_normalized_matrix[0])\n",
        "  negative_ideal_solution = np.zeros_like(weighted_normalized_matrix[0])\n",
        "\n",
        "  # Calculate the distances to the ideal and negative ideal solutions.\n",
        "  distances_to_ideal = np.linalg.norm(weighted_normalized_matrix - ideal_solution, axis=1)\n",
        "  distances_to_negative_ideal = np.linalg.norm(weighted_normalized_matrix - negative_ideal_solution, axis=1)\n",
        "\n",
        "  # Calculate the relative closeness to the ideal solution (PI).\n",
        "  performance_index = distances_to_negative_ideal / (distances_to_negative_ideal + distances_to_ideal)\n",
        "\n",
        "  # Return the index of the model with the highest PI.\n",
        "  return np.argmax(performance_index)\n",
        "\n",
        "# Example usage:\n",
        "\n",
        "# Define some sample models and metrics.\n",
        "models = [\n",
        "    {\"BLEU\": 0.85, \"ROUGE\": 0.78, \"Perplexity\": 1.23},\n",
        "    {\"BLEU\": 0.90, \"ROUGE\": 0.82, \"Perplexity\": 1.15},\n",
        "    {\"BLEU\": 0.82, \"ROUGE\": 0.75, \"Perplexity\": 1.30},\n",
        "]\n",
        "metrics = [\"BLEU\", \"ROUGE\", \"Perplexity\"]\n",
        "weights = [0.4, 0.3, 0.3]  # Adjust weights as needed\n",
        "\n",
        "# Find the best model.\n",
        "best_model_index = topsis(models, metrics, weights)\n",
        "best_model = models[best_model_index]\n",
        "\n",
        "print(\"Best model:\", best_model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZiEl_1-btsk",
        "outputId": "7cef1c1c-a5b9-4c79-fff6-d1372a7448ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model: {'BLEU': 0.9, 'ROUGE': 0.82, 'Perplexity': 1.15}\n"
          ]
        }
      ]
    }
  ]
}